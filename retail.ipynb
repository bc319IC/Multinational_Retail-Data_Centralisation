{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import database_utils\n",
    "import data_extraction\n",
    "import data_cleaning\n",
    "from sqlalchemy import create_engine, types\n",
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available tables: ['legacy_store_details', 'dim_card_details', 'legacy_users', 'orders_table']\n"
     ]
    }
   ],
   "source": [
    "# Initialise the connector, extractor, and cleaner\n",
    "db_connector = database_utils.DatabaseConnector()\n",
    "extractor = data_extraction.DataExtractor()\n",
    "data_cleaner = data_cleaning.DataCleaning()\n",
    "\n",
    "# Initialise a connection to the local PostgreSQL database\n",
    "file_path = \"postgres_creds.yaml\"\n",
    "with open(file_path, 'r') as file:\n",
    "    post_creds = yaml.safe_load(file)\n",
    "local_db_engine = create_engine(f\"postgresql://{post_creds['username']}:{post_creds['password']}@localhost:5432/sales_data\")\n",
    "\n",
    "# List all tables in the RDS database\n",
    "tables = db_connector.list_db_tables()\n",
    "print(\"Available tables:\", tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Users Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the users data from the specified table\n",
    "users_df = extractor.read_rds_table(db_connector, 'legacy_users')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the users data\n",
    "cleaned_users_df = data_cleaner.clean_user_data(users_df)\n",
    "\n",
    "# Column types dic\n",
    "users_dtype_dic = {\n",
    "'first_name': types.VARCHAR(length=255), \n",
    "'last_name': types.VARCHAR(length=255), \n",
    "'date_of_birth': types.DATE, \n",
    "'country_code': types.VARCHAR(length=2), \n",
    "'user_uuid': types.UUID, \n",
    "'join_date': types.DATE\n",
    "}\n",
    "\n",
    "# Upload the cleaned data to the local database\n",
    "#db_connector.upload_to_db(cleaned_users_df, 'dim_users', local_db_engine, users_dtype_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Card Details Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the cards data from the specified link\n",
    "pdf_link = 'https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf'\n",
    "cards_df = extractor.retrieve_pdf_data(pdf_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the cards data\n",
    "cleaned_cards_df = data_cleaner.clean_card_data(cards_df)\n",
    "\n",
    "# Column types dic\n",
    "cards_dtype_dic = {\n",
    "'card_number': types.VARCHAR(length=19), \n",
    "'expiry_date': types.VARCHAR(length=5), \n",
    "'date_payment_confirmed': types.DATE\n",
    "}\n",
    "\n",
    "# Upload the cleaned data to the local database\n",
    "#db_connector.upload_to_db(cleaned_cards_df, 'dim_card_details', local_db_engine, cards_dtype_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stores Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_stores_endpoint = \"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores\"\n",
    "store_details_endpoint = \"https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/{store_number}\"\n",
    "\n",
    "# Get the number of stores\n",
    "number_of_stores = extractor.list_number_of_stores(number_of_stores_endpoint)\n",
    "\n",
    "# Retrieve data for all stores\n",
    "if number_of_stores:\n",
    "    stores_df = extractor.retrieve_stores_data(store_details_endpoint, number_of_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the stores data\n",
    "cleaned_stores_df = data_cleaner.clean_store_data(stores_df)\n",
    "\n",
    "# Column types dic\n",
    "stores_dtype_dic = {\n",
    "'longitude': types.FLOAT, \n",
    "'locality': types.VARCHAR(length=255), \n",
    "'store_code': types.VARCHAR(length=11), \n",
    "'staff_numbers': types.SMALLINT, \n",
    "'opening_date': types.DATE, \n",
    "'store_type': types.VARCHAR(length=255),\n",
    "'latitude': types.FLOAT, \n",
    "'country_code': types.VARCHAR(length=2), \n",
    "'continent': types.VARCHAR(length=255)\n",
    "}\n",
    "\n",
    "# Upload the cleaned data to the local database\n",
    "#db_connector.upload_to_db(cleaned_stores_df, 'dim_store_details', local_db_engine, stores_dtype_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Products Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the products data from S3\n",
    "products_df = extractor.extract_csv_from_s3('s3://data-handling-public/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert weights\n",
    "products_df = data_cleaner.convert_product_weights(products_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the products data\n",
    "cleaned_products_df = data_cleaner.clean_product_data(products_df)\n",
    "\n",
    "# Column types dic\n",
    "products_dtype_dic = {\n",
    "'product_price': types.FLOAT, \n",
    "'weight': types.FLOAT, \n",
    "'ean': types.VARCHAR(length=17), \n",
    "'product_code': types.VARCHAR(length=11), \n",
    "'date_added': types.DATE, \n",
    "'uuid': types.UUID,\n",
    "'still_available': types.BOOLEAN, \n",
    "'weight_class': types.VARCHAR(length=14)\n",
    "}\n",
    "\n",
    "# Upload the cleaned data to the local database\n",
    "#db_connector.upload_to_db(cleaned_products_df, 'dim_products', local_db_engine, products_dtype_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Orders Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the orders data from the specified table\n",
    "orders_df = extractor.read_rds_table(db_connector, 'orders_table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the orders data\n",
    "cleaned_orders_df = data_cleaner.clean_order_data(orders_df)\n",
    "\n",
    "# Column types dic\n",
    "orders_dtype_dic = {\n",
    "'date_uuid': types.UUID, \n",
    "'user_uuid': types.UUID, \n",
    "'card_number': types.VARCHAR(length=19), \n",
    "'store_code': types.VARCHAR(length=12), \n",
    "'product_code': types.VARCHAR(length=11), \n",
    "'product_quantity': types.SMALLINT\n",
    "}\n",
    "\n",
    "# Upload the cleaned data to the local database\n",
    "#db_connector.upload_to_db(cleaned_orders_df, 'orders_table', local_db_engine, orders_dtype_dic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dates Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the dates data from the specified link\n",
    "dates_df = extractor.retrieve_json_data('https://data-handling-public.s3.eu-west-1.amazonaws.com/date_details.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\brand\\Desktop\\multinational-retail-data-centralisation271\\data_cleaning.py:284: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "# Clean the dates data\n",
    "cleaned_dates_df = data_cleaner.clean_date_data(dates_df)\n",
    "\n",
    "# Column types dic\n",
    "dates_dtype_dic = {\n",
    "'date': types.DATE, \n",
    "'time_period': types.VARCHAR(length=10), \n",
    "'date_uuid': types.UUID\n",
    "}\n",
    "\n",
    "# Upload the cleaned data to the local database\n",
    "#db_connector.upload_to_db(cleaned_dates_df, 'dim_date_times', local_db_engine, dates_dtype_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8\n",
       "1         8fe96c3a-d62d-4eb5-b313-cf12d9126a49\n",
       "2         fc461df4-b919-48b2-909e-55c95a03fe6b\n",
       "3         6104719f-ef14-4b09-bf04-fb0c4620acb0\n",
       "4         9523a6d3-b2dd-4670-a51a-36aebc89f579\n",
       "                          ...                 \n",
       "120118    95c74b0a-d495-4359-b1c0-e2da511e8403\n",
       "120119    5d6fa6fe-e583-4baf-8bbb-d1dd6e2b551f\n",
       "120120    48b7f1fc-db13-4611-ad8e-3dac0b759488\n",
       "120121    51c0b538-7ded-4697-8e84-9f7aa13f9112\n",
       "120122    e74907ca-1a4a-476c-a3ca-6b898b0964c2\n",
       "Name: user_uuid, Length: 120123, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
